{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\tokenizer.py:214: FutureWarning: Possible nested set at position 3397\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n",
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\tokenizer.py:214: FutureWarning: Possible nested set at position 3927\n",
      "  self.tok = re.compile(r'({})'.format('|'.join(pipeline)))\n"
     ]
    }
   ],
   "source": [
    "import instaloader\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pytesseract\n",
    "import malaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded session from session-faizgram.\n"
     ]
    }
   ],
   "source": [
    "L = instaloader.Instaloader()\n",
    "\n",
    "USERNAME = \"faizgram\"\n",
    "SESSION_FILE = \"session-faizgram\"\n",
    "\n",
    "try:\n",
    "    L.load_session_from_file(username=USERNAME, filename=SESSION_FILE)\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Session file not found. Please log in manually using Instaloader CLI.\")\n",
    "    exit()\n",
    "except instaloader.ConnectionException as e:\n",
    "   print(f\"Connection exception {e}\")\n",
    "   exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_hashtag(hashtag, limit, profile_name=None, location=None):\n",
    "    post_count = 0\n",
    "    hashtag_posts = pd.DataFrame(columns=[\"Thumb\", \"Caption\", \"Comment\"])\n",
    "    thumbs = []\n",
    "    captions = []\n",
    "    comments = []\n",
    "    dates = []\n",
    "\n",
    "    posts = L.get_hashtag_posts(hashtag)\n",
    "\n",
    "    for post in posts:\n",
    "        if post.caption:\n",
    "            thumbs.append(post.url)\n",
    "            captions.append(post.caption)\n",
    "            comments.append(post.comments)\n",
    "            dates.append(post.date)\n",
    "            # print(f\"Extracted caption: {post.caption}\")\n",
    "        \n",
    "        post_count += 1\n",
    "        if post_count >= limit:\n",
    "            break\n",
    "\n",
    "    hashtag_posts[\"Thumb\"] = thumbs\n",
    "    hashtag_posts[\"Caption\"] = captions\n",
    "    hashtag_posts[\"Date\"] = dates\n",
    "    hashtag_posts[\"Comment\"] = comments\n",
    "\n",
    "    return hashtag_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = by_hashtag(\"unikl\", 5, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thumb</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://instagram.fkul4-4.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>CONVO DAY IPG MALAYSIA  24!\\nKONVO DAH NAK DEK...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 16:28:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://instagram.fkul4-5.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>CONVO DAY IPG MALAYSIA  24!\\nKONVO DAH NAK DEK...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 16:22:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://instagram.fkul4-3.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>Train SCS Class 92 üöù\\n\\nGambar sekitar Majlis ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 15:16:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://instagram.fkul4-3.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>‚ù§Ô∏è‚ù§Ô∏èRUN‚ù§Ô∏è‚ù§Ô∏è\\nSouthern Bundle Collection\\n\\nNB ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 13:39:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://instagram.fkul4-5.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>‚ù§Ô∏è‚ù§Ô∏èCOURT‚ù§Ô∏è‚ù§Ô∏è\\nSouthern Bundle Collection\\n\\nA...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 12:35:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Thumb  \\\n",
       "0  https://instagram.fkul4-4.fna.fbcdn.net/v/t51....   \n",
       "1  https://instagram.fkul4-5.fna.fbcdn.net/v/t51....   \n",
       "2  https://instagram.fkul4-3.fna.fbcdn.net/v/t51....   \n",
       "3  https://instagram.fkul4-3.fna.fbcdn.net/v/t51....   \n",
       "4  https://instagram.fkul4-5.fna.fbcdn.net/v/t51....   \n",
       "\n",
       "                                             Caption  Comment  \\\n",
       "0  CONVO DAY IPG MALAYSIA  24!\\nKONVO DAH NAK DEK...        0   \n",
       "1  CONVO DAY IPG MALAYSIA  24!\\nKONVO DAH NAK DEK...        0   \n",
       "2  Train SCS Class 92 üöù\\n\\nGambar sekitar Majlis ...        0   \n",
       "3  ‚ù§Ô∏è‚ù§Ô∏èRUN‚ù§Ô∏è‚ù§Ô∏è\\nSouthern Bundle Collection\\n\\nNB ...        0   \n",
       "4  ‚ù§Ô∏è‚ù§Ô∏èCOURT‚ù§Ô∏è‚ù§Ô∏è\\nSouthern Bundle Collection\\n\\nA...        0   \n",
       "\n",
       "                 Date  \n",
       "0 2024-12-10 16:28:40  \n",
       "1 2024-12-10 16:22:35  \n",
       "2 2024-12-10 15:16:46  \n",
       "3 2024-12-10 13:39:19  \n",
       "4 2024-12-10 12:35:53  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mohdf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\mohdf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mohdf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import pipeline\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Tesseract path (Windows 10/11)\n",
    "tesseract_path = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Unix/Linux\n",
    "\n",
    "# MacOS\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = tesseract_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text: \n",
      "Extracted text: \n",
      "Extracted text: \n",
      "Extracted text: \n",
      "Extracted text: \n"
     ]
    }
   ],
   "source": [
    "img_texts = []\n",
    "for img_url in posts[\"Thumb\"]:\n",
    "    response = requests.get(img_url)\n",
    "    img_text = pytesseract.image_to_string(Image.open(BytesIO(response.content)))\n",
    "    print(f\"Extracted text: {img_text}\")\n",
    "    img_texts.append(img_text)\n",
    "\n",
    "posts[\"Thumb Text\"] = img_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thumb</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Thumb Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://instagram.fkul4-4.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>CONVO DAY IPG MALAYSIA  24!\\nKONVO DAH NAK DEK...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 16:28:40</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://instagram.fkul4-5.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>CONVO DAY IPG MALAYSIA  24!\\nKONVO DAH NAK DEK...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 16:22:35</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://instagram.fkul4-3.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>Train SCS Class 92 üöù\\n\\nGambar sekitar Majlis ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 15:16:46</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://instagram.fkul4-3.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>‚ù§Ô∏è‚ù§Ô∏èRUN‚ù§Ô∏è‚ù§Ô∏è\\nSouthern Bundle Collection\\n\\nNB ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 13:39:19</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://instagram.fkul4-5.fna.fbcdn.net/v/t51....</td>\n",
       "      <td>‚ù§Ô∏è‚ù§Ô∏èCOURT‚ù§Ô∏è‚ù§Ô∏è\\nSouthern Bundle Collection\\n\\nA...</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-12-10 12:35:53</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Thumb  \\\n",
       "0  https://instagram.fkul4-4.fna.fbcdn.net/v/t51....   \n",
       "1  https://instagram.fkul4-5.fna.fbcdn.net/v/t51....   \n",
       "2  https://instagram.fkul4-3.fna.fbcdn.net/v/t51....   \n",
       "3  https://instagram.fkul4-3.fna.fbcdn.net/v/t51....   \n",
       "4  https://instagram.fkul4-5.fna.fbcdn.net/v/t51....   \n",
       "\n",
       "                                             Caption  Comment  \\\n",
       "0  CONVO DAY IPG MALAYSIA  24!\\nKONVO DAH NAK DEK...        0   \n",
       "1  CONVO DAY IPG MALAYSIA  24!\\nKONVO DAH NAK DEK...        0   \n",
       "2  Train SCS Class 92 üöù\\n\\nGambar sekitar Majlis ...        0   \n",
       "3  ‚ù§Ô∏è‚ù§Ô∏èRUN‚ù§Ô∏è‚ù§Ô∏è\\nSouthern Bundle Collection\\n\\nNB ...        0   \n",
       "4  ‚ù§Ô∏è‚ù§Ô∏èCOURT‚ù§Ô∏è‚ù§Ô∏è\\nSouthern Bundle Collection\\n\\nA...        0   \n",
       "\n",
       "                 Date Thumb Text  \n",
       "0 2024-12-10 16:28:40             \n",
       "1 2024-12-10 16:22:35             \n",
       "2 2024-12-10 15:16:46             \n",
       "3 2024-12-10 13:39:19             \n",
       "4 2024-12-10 12:35:53             "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # this uses NLTK\n",
    "    # tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # this uses malaya toolkit\n",
    "    tokenizer = malaya.tokenizer.Tokenizer()    \n",
    "    tokens = tokenizer.tokenize(text, lowercase=True)\n",
    "\n",
    "    # remove alphanumeric word(s)\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum()]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convo day ipg malaysia 24 konvo dah nak dekat dah kenangan bersama sahabat wajib ada untuk kali terakhirr jom tempah photographer convobyzown promotion harga sekarang officials photographer lihat hasil shoot konvo di gambar anda akan diberikan melalui telegram tau',\n",
       " 'convo day ipg malaysia 24 konvo dah nak dekat dah kenangan bersama sahabat wajib ada untuk kali terakhirr jom tempah photographer convobyzown promotion harga sekarang officials photographer lihat hasil shoot konvo di gambar anda akan diberikan melalui telegram tau',\n",
       " 'train scs class 92 gambar sekitar majlis penyerahan handback ceremony tren scs class 92 projek maintenance repair overhaul mro dan perjanjian kolaborasi collaboration agreement di antara m rail technics railtec dengan universiti kuala lumpur unikl oleh yab dato seri ahmad zahid bin hamidi timbalan perdana menteri malaysia',\n",
       " 'run southern bundle collection nb 411 all black so ringan size 9uk kondisi rm 128 free pos semenanjung',\n",
       " 'court southern bundle collection as1cs bladelyte size 8uk 27cm kondisi rm 110 free pos semenanjung']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "for text in posts[\"Caption\"]:\n",
    "   texts.append(preprocess_text(text))\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0d1f163b544b31926371dba00fdd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "multinomial.pkl:   0%|          | 0.00/3.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mohdf\\.cache\\huggingface\\hub\\models--huseinzol05--v47-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67bd34379b94dd0bfb0e8f6782be65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tfidf.pkl:   0%|          | 0.00/2.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc425c2fff864762a40f733ae1ac4440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.model:   0%|          | 0.00/875k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ComplementNB from version 0.22.1 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.22.1 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22.1 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "youtokentome not installed. Please install it by `pip install youtokentome` and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\text\\bpe.py:140\u001b[0m, in \u001b[0;36mYTTMEncoder.__init__\u001b[1;34m(self, vocab_file, id_mode, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myoutokentome\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myttm\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'youtokentome'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sent_model \u001b[38;5;241m=\u001b[39m \u001b[43mmalaya\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\sentiment.py:37\u001b[0m, in \u001b[0;36mmultinomial\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmultinomial\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    Load multinomial sentiment model.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    result : malaya.model.ml.Bayes class\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPATH_SENTIMENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms3_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS3_PATH_SENTIMENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\supervised\\classification.py:21\u001b[0m, in \u001b[0;36mmultinomial\u001b[1;34m(path, s3_path, module, label, sigmoid, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fopen:\n\u001b[0;32m     19\u001b[0m     vectorize \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fopen)\n\u001b[1;32m---> 21\u001b[0m bpe \u001b[38;5;241m=\u001b[39m \u001b[43mYTTMEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbpe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m naive()\n\u001b[0;32m     24\u001b[0m cleaning \u001b[38;5;241m=\u001b[39m partial(classification_textcleaning_stemmer, stemmer\u001b[38;5;241m=\u001b[39mstemmer)\n",
      "File \u001b[1;32mc:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\text\\bpe.py:142\u001b[0m, in \u001b[0;36mYTTMEncoder.__init__\u001b[1;34m(self, vocab_file, id_mode, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myoutokentome\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myttm\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myoutokentome not installed. Please install it by `pip install youtokentome` and try again.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m id_mode:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m yttm\u001b[38;5;241m.\u001b[39mOutputType\u001b[38;5;241m.\u001b[39mID\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: youtokentome not installed. Please install it by `pip install youtokentome` and try again."
     ]
    }
   ],
   "source": [
    "# load model\n",
    "sent_model = malaya.sentiment.multinomial()\n",
    "\n",
    "sentiments = []\n",
    "sentiment_probas = []\n",
    "for text in texts:\n",
    "    sentiments.append(sent_model.predict(text))\n",
    "    sentiment_probas = (sent_model.predict_proba(text))\n",
    "\n",
    "posts[\"Sentiment\"] = sentiments\n",
    "posts[\"Probability\"] = sentiment_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e5b406d1914bd9a4190c378af536ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "multinomial.pkl:   0%|          | 0.00/6.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mohdf\\.cache\\huggingface\\hub\\models--huseinzol05--v34-emotion. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6afb1f097f94752bd2b655f31406032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tfidf.pkl:   0%|          | 0.00/2.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acbd6fa9fae4492ae19553b6c8a5b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.model:   0%|          | 0.00/881k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ComplementNB from version 0.22.1 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 0.22.1 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 0.22.1 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "youtokentome not installed. Please install it by `pip install youtokentome` and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\text\\bpe.py:140\u001b[0m, in \u001b[0;36mYTTMEncoder.__init__\u001b[1;34m(self, vocab_file, id_mode, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myoutokentome\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myttm\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'youtokentome'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmalaya\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memotion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mpredict(text)\n",
      "File \u001b[1;32mc:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\emotion.py:37\u001b[0m, in \u001b[0;36mmultinomial\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmultinomial\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    Load multinomial emotion model.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    result: malaya.model.ml.MulticlassBayes class\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPATH_EMOTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms3_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS3_PATH_EMOTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memotion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\supervised\\classification.py:21\u001b[0m, in \u001b[0;36mmultinomial\u001b[1;34m(path, s3_path, module, label, sigmoid, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fopen:\n\u001b[0;32m     19\u001b[0m     vectorize \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fopen)\n\u001b[1;32m---> 21\u001b[0m bpe \u001b[38;5;241m=\u001b[39m \u001b[43mYTTMEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbpe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m naive()\n\u001b[0;32m     24\u001b[0m cleaning \u001b[38;5;241m=\u001b[39m partial(classification_textcleaning_stemmer, stemmer\u001b[38;5;241m=\u001b[39mstemmer)\n",
      "File \u001b[1;32mc:\\Users\\mohdf\\anaconda\\envs\\work\\Lib\\site-packages\\malaya\\text\\bpe.py:142\u001b[0m, in \u001b[0;36mYTTMEncoder.__init__\u001b[1;34m(self, vocab_file, id_mode, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myoutokentome\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myttm\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myoutokentome not installed. Please install it by `pip install youtokentome` and try again.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m id_mode:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m yttm\u001b[38;5;241m.\u001b[39mOutputType\u001b[38;5;241m.\u001b[39mID\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: youtokentome not installed. Please install it by `pip install youtokentome` and try again."
     ]
    }
   ],
   "source": [
    "model = malaya.emotion.multinomial()\n",
    "\n",
    "for text in texts:\n",
    "    model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
